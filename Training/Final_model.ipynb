{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_model.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "gmjgWGeOgBUA",
        "v12gXXuCfRfb",
        "Q58bT6NfgIIv",
        "W47j8fCfgP2W",
        "Rsg27WBIg1N_",
        "mMsAVjcsB4sg",
        "k23rm_jOg9Iv"
      ],
      "authorship_tag": "ABX9TyNayC8BbL8GMjKZbpFvgvIW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohannashahrad/Borealis_AI_Plant_Tree_Project/blob/main/Final_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0GQyvaEf4Gj"
      },
      "source": [
        "#Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1Zz4JCUj8Lr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "ef2b3624-cb58-483c-a630-27cf7859116e"
      },
      "source": [
        "# Import all the required libraries\n",
        "import sys\n",
        "!{sys.executable} -m pip install darts\n",
        "from funcs import *\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import seaborn as sns\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a7300550ce03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Import all the required libraries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfuncs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'funcs'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmjgWGeOgBUA"
      },
      "source": [
        "#Loading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "t3LlSoiOkISl",
        "outputId": "32738a6a-3a18-4fa4-805d-4c640248261c"
      },
      "source": [
        "# Loading DataSet\n",
        "df = load_DF('https://raw.githubusercontent.com/mohannashahrad/Borealis_AI_Plant_Tree_Project/main/Final_Data/final_data2.csv')\n",
        "df = df.iloc[: , 1:]\n",
        "display(df.head(30))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-f75dc54b739e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Loading DataSet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_DF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://raw.githubusercontent.com/mohannashahrad/Borealis_AI_Plant_Tree_Project/main/Final_Data/final_data2.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'load_DF' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v12gXXuCfRfb"
      },
      "source": [
        "#Preprocessing \n",
        "\n",
        "This section consists of data normalization and one-hot encoding for discrete features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHVMh9Fh5Xtg"
      },
      "source": [
        "df = df[~df.isin([np.nan, np.inf, -np.inf]).any(1)]\n",
        "col_names = ['Land Area (m2)', 'Agriculture Land (m2)', 'Forest Land (m2)', 'Population', 'Pop Growth (%)', 'Urban Pop (%)',\n",
        "                'GDP (US$)', 'GDP Growth (%)', 'Forest Rents (% GDP)', 'Coal Rents (% GDP)', 'Oil Rents (% GDP)', 'CO2 Emission (kt)',\n",
        "                'GHG Emision (CO2 eqv)']\n",
        "\n",
        "df = standardize(df,col_names)\n",
        "discrete_columns = [\"Country Name\"]\n",
        "country_names = df[\"Country Name\"]\n",
        "df = oneHotEncode(df,discrete_columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q58bT6NfgIIv"
      },
      "source": [
        "# Splitting the dataset into test and train sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpzsha8TrOQW"
      },
      "source": [
        "# Splitting the dataset into training and test parts\n",
        "y = df['Tree Loss (ha)']\n",
        "x = df.loc[:, df.columns != 'Tree Loss (ha)']\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W47j8fCfgP2W"
      },
      "source": [
        "# Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0olGTIQ8sbnw"
      },
      "source": [
        "model = LinearRegression()  \n",
        "model.fit(X_train, y_train) \n",
        "y_pred = model.predict(X_test)\n",
        "print_analysis(y_pred, y_test)\n",
        "compare_results(y_pred, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rsg27WBIg1N_"
      },
      "source": [
        "# XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idC-jChF1nf6"
      },
      "source": [
        "dtrain = xgb.DMatrix(data=X_train,label=y_train)\n",
        "params = {\n",
        "    'gamma':0,                 \n",
        "    'learning_rate':0.07,\n",
        "    'max_depth':5,\n",
        "    'min_child_weight':1.5,\n",
        "    'n_estimators':1000,                                                                    \n",
        "    'reg_alpha':0.75,\n",
        "    'reg_lambda':0.45,\n",
        "    'subsample':0.6,\n",
        "    'seed':42\n",
        "}\n",
        "cv_results = xgb.cv(\n",
        "    params,\n",
        "    dtrain,\n",
        "    num_boost_round=999,\n",
        "    seed=42,\n",
        "    nfold=5,\n",
        "    metrics={'mae'},\n",
        "    early_stopping_rounds=10\n",
        ")\n",
        "cv_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMsAVjcsB4sg"
      },
      "source": [
        "#Hyper parameter Tuning for XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Fk9ny_-3A7s"
      },
      "source": [
        "gridsearch_params = [\n",
        "    (max_depth, min_child_weight)\n",
        "    for max_depth in range(4,10)\n",
        "    for min_child_weight in range(1,8)\n",
        "]\n",
        "\n",
        "min_mae = float(\"Inf\")\n",
        "best_params = None\n",
        "for max_depth, min_child_weight in gridsearch_params:\n",
        "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
        "                             max_depth,\n",
        "                             min_child_weight))\n",
        "    # Update our parameters\n",
        "    params['max_depth'] = max_depth\n",
        "    params['min_child_weight'] = min_child_weight\n",
        "    # Run CV\n",
        "    cv_results = xgb.cv(\n",
        "        params,\n",
        "        dtrain,\n",
        "        num_boost_round=1000,\n",
        "        seed=42,\n",
        "        nfold=5,\n",
        "        metrics={'mae'},\n",
        "        early_stopping_rounds=10\n",
        "    )\n",
        "    # Update best MAE\n",
        "    mean_mae = cv_results['test-mae-mean'].min()\n",
        "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
        "    print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\n",
        "    if mean_mae < min_mae:\n",
        "        min_mae = mean_mae\n",
        "        best_params = (max_depth,min_child_weight)\n",
        "print(\"Best params: {}, {}, MAE: {}\".format(best_params[0], best_params[1], min_mae))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3K3WdPCzWEW"
      },
      "source": [
        "data_dmatrix = xgb.DMatrix(data=x,label=y)\n",
        "xg_reg = xgb.XGBRegressor(colsample_bytree=0.4,\n",
        "                 gamma=0,                 \n",
        "                 learning_rate=0.07,\n",
        "                 max_depth=8,\n",
        "                 min_child_weight=3,\n",
        "                 n_estimators=1000,                                                                    \n",
        "                 reg_alpha=0.75,\n",
        "                 reg_lambda=0.45,\n",
        "                 subsample=0.6,\n",
        "                 seed=42)\n",
        "xg_reg.fit(X_train,y_train)\n",
        "\n",
        "y_pred = xg_reg.predict(X_test)\n",
        "print_analysis(y_pred, y_test)\n",
        "compare_results(y_pred, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k23rm_jOg9Iv"
      },
      "source": [
        "#Feature Importance using XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5mm0j9rEL6C"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.bar(range(14), xg_reg.feature_importances_[:14])\n",
        "LABELS = x.columns[:14]\n",
        "plt.xticks(range(len(xg_reg.feature_importances_[:14])), LABELS, rotation='vertical')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}